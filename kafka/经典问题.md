# 经典问题

## kafka 的 Rebalance 过程

### 触发 Rebalance 的条件

* 有新的 consumer 加入
* 有旧的 consumer 挂了
* topic 的 partition 增加

### Rebalance 的影响

1、可能重复消费: Consumer被踢出消费组，可能还没有提交offset，Rebalance时会Partition重新分配其它Consumer,会造成重复消费，虽有幂等操作但耗费消费资源，亦增加集群压力

2、集群不稳定：Rebalance扩散到整个ConsumerGroup的所有消费者，因为一个消费者的退出，导致整个Group进行了Rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大

3、影响消费速度：频繁的Rebalance反而降低了消息的消费速度，大部分时间都在重复消费和Rebalance

### Rebalanc 过程

Group Coordinator是一个服务，每个 Broker 在启动的时候都会启动一个该服务。Group Coordinator 的作用是用来存储Group的相关Meta信息，并将对应Partition的Offset信息记录到Kafka内置Topic( consumer_offsets )中。Kafka在0.9之前是基于Zookeeper来存储Partition的Offset信息，因为ZK并不适用于频繁的写操作，所以在0.9之后通过内置Topic的方式来记录对应Partition的Offset。

每个Group都会选择一个Coordinator来完成自己组内各Partition的Offset信息。那么 consumer group 如何确定自己的 coordinator 是谁呢？ 简单来说分为两步：

* 确定 consumer group 位移信息写入 consumers_offsets 的哪个分区。具体计算公式：partition_num = Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount) 

* 该分区 leader 所在的 broker 就是被选定的 coordinator

rebalance过程分为2步：Join和Sync

Join， 顾名思义就是加入组。这一步中，所有成员都向coordinator发送JoinGroup请求，请求入组。一旦所有成员都发送了JoinGroup请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader——注意leader和coordinator不是一个概念。leader负责消费分配方案的制定。
Sync，这一步leader开始分配消费方案，即哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案封装进SyncGroup请求中发给coordinator，非leader也会发SyncGroup请求，只是内容为空。coordinator接收到分配方案之后会把方案塞进SyncGroup的response中发给各个consumer。这样组内的所有成员就都知道自己应该消费哪些分区了。

### 如何尽量避免 Rebalance？

首先，有些业务需要是无法避免 rebalance 的，例如针对分区个数的增加， 一般不会常有，是需要增加的时候都是业务及数据需求，不可避免，还有对 Topic 的订阅增加或取消亦不可避免。可以通过合理设置消费者端参数尽量避免 rebalance 的情况：

（1）未能及时发送心跳而 Rebalance

session.timeout.ms  一次 session 的连接超时时间

heartbeat.interval.ms  心跳时间，一般为超时时间的1/3，Consumer在被判定为死亡之前，能够发送至少 3 轮的心跳请求

（2）Consumer 消费超时而 Rebalance

max.poll.interval.ms  每隔多长时间去拉取消息。合理设置预期值，尽量但间隔时间消费者处理完业务逻辑，否则就会被 coordinator 判定为死亡，踢出 Consumer Group，进行 Rebalance

max.poll.records  一次从拉取出来的数据条数。根据消费业务处理耗费时长合理设置，如果每次max.poll.interval.ms 设置的时间较短，可以 max.poll.records 设置小点儿，少拉取些，这样不会超时。

## 如何保证消息不丢失？

### 生产者端



### Broker 端

做好冗余备份

## 如何保证不重复消费？

